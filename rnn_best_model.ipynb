{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "rnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePM6_1SnvC4x",
        "outputId": "a2c05793-847c-4ffc-9161-e819e8f9ef9e"
      },
      "source": [
        "!wget https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
        "!tar -xf 'dakshina_dataset_v1.0.tar'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-20 17:04:11--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 173.194.203.128, 173.194.202.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2008340480 (1.9G) [application/x-tar]\n",
            "Saving to: ‘dakshina_dataset_v1.0.tar’\n",
            "\n",
            "dakshina_dataset_v1 100%[===================>]   1.87G  41.1MB/s    in 17s     \n",
            "\n",
            "2021-05-20 17:04:28 (112 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PykGwNNuekt",
        "outputId": "bdb08f20-b8a7-4435-981d-09f75519f0d3"
      },
      "source": [
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "from importlib import reload\n",
        "import RNN\n",
        "RNN = reload(RNN)\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 25  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space. #hidden states hyperparameter\n",
        "# Path to the data txt file on disk.\n",
        "train_data = \"dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\"\n",
        "val_data = \"dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.dev.tsv\"\n",
        "# open and save the files to lists\n",
        "with open(train_data, \"r\", encoding=\"utf-8\") as f:\n",
        "    train_lines = f.read().split(\"\\n\")\n",
        "with open(val_data, \"r\", encoding=\"utf-8\") as f:\n",
        "    val_lines = f.read().split(\"\\n\")\n",
        "# popping the last element of all the lists since it is empty character\n",
        "train_lines.pop()\n",
        "val_lines.pop()\n",
        "random.shuffle(train_lines)\n",
        "print(train_lines[0:2])\n",
        "\n",
        "# embedding pre processing\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "# go through the train lines and split them into 3 and save input and target\n",
        "for line in train_lines[: (len(train_lines) - 1)]:\n",
        "    # because we want english to devanagiri conversion\n",
        "    target_text, input_text, _ = line.split(\"\\t\")\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = \"\\t\" + target_text + \"\\n\"\n",
        "    # append it to the main input texts list\n",
        "    input_texts.append(input_text)\n",
        "    # append it to the main target texts list\n",
        "    target_texts.append(target_text)\n",
        "    # to find the number of unique characters in both\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "# add the space character to both\n",
        "input_characters.add(\" \")\n",
        "target_characters.add(\" \")\n",
        "# sort it\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "# find the number\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "# find the maximum length of input word and target word\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "# create an index\n",
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "print((input_token_index))\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "print((target_token_index))\n",
        "# create an 0 array for encoder input size of (input_texts,max_seqlen,tokens)\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "# create decoder input\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "# create decoder target\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "# for each sample convert it into character encoding i.e. if\n",
        "# at that position a character is present then encode the index of that character there\n",
        "# this is done for both encoder and decoder input data for further word embedding\n",
        "# but target data is one hot encoded.\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t] = input_token_index[char]\n",
        "    # remaining positions set as empty space\n",
        "    encoder_input_data[i, t + 1:] = input_token_index[\" \"]\n",
        "    # similarly do for decoder data\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t] = target_token_index[char]\n",
        "        # check if t >0 since decoder targer data is ahead\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    # append both the remaining positions of both the datas with empty space\n",
        "    decoder_input_data[i, t + 1:] = target_token_index[\" \"]\n",
        "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
        "\n",
        "# embedding validation\n",
        "# for validation data, almost same\n",
        "val_input_texts = []\n",
        "val_target_texts = []\n",
        "for line in val_lines[: (len(val_lines) - 1)]:\n",
        "    target_text, input_text, _ = line.split(\"\\t\")\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = \"\\t\" + target_text + \"\\n\"\n",
        "    val_input_texts.append(input_text)\n",
        "    val_target_texts.append(target_text)\n",
        "val_max_encoder_seq_length = max([len(txt) for txt in val_input_texts])\n",
        "val_max_decoder_seq_length = max([len(txt) for txt in val_target_texts])\n",
        "val_encoder_input_data = np.zeros(\n",
        "    (len(val_input_texts), val_max_encoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "val_decoder_input_data = np.zeros(\n",
        "    (len(val_input_texts), val_max_decoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "val_decoder_target_data = np.zeros(\n",
        "    (len(val_input_texts), val_max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "for i, (input_text, target_text) in enumerate(zip(val_input_texts, val_target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        val_encoder_input_data[i, t] = input_token_index[char]\n",
        "    val_encoder_input_data[i, t + 1:] = input_token_index[\" \"]\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        val_decoder_input_data[i, t] = target_token_index[char]\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            val_decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    val_decoder_input_data[i, t + 1:] = target_token_index[\" \"]\n",
        "    val_decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
        "\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
        "\n",
        "# create RNN model\n",
        "model = RNN.RNN(embedding_size=256, n_encoder_tokens=num_encoder_tokens, n_decoder_tokens=num_decoder_tokens,\n",
        "                n_encoder_layers=2, n_decoder_layers=3, latent_dimension=latent_dim,\n",
        "                cell_type='lstm', target_token_index=target_token_index, max_decoder_seq_length=max_decoder_seq_length,\n",
        "                reverse_target_char_index=reverse_target_char_index, dropout=0.2)\n",
        "model.fit(encoder_input_data, decoder_input_data, decoder_target_data,\n",
        "          batch_size, epochs=epochs\n",
        "          )\n",
        "# subset = 100\n",
        "# val_accuracy = model.accuracy(val_encoder_input_data[0:subset], val_target_texts[0:subset]) if subset>0 \\\n",
        "#     else model.accuracy(val_encoder_input_data, val_target_texts)\n",
        "# print('Validation accuracy: ', val_accuracy)\n",
        "\n",
        "# compute test accuracy\n",
        "print('Reading test data')\n",
        "test_data = \"dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.test.tsv\"\n",
        "# open and save the files to lists\n",
        "with open(test_data, \"r\", encoding=\"utf-8\") as f:\n",
        "    test_lines = f.read().split(\"\\n\")\n",
        "# popping the last element of all the lists since it is empty character\n",
        "test_lines.pop()\n",
        "# embedding test\n",
        "# for test data, almost same\n",
        "test_input_texts = []\n",
        "test_target_texts = []\n",
        "for line in test_lines[: (len(test_lines) - 1)]:\n",
        "    target_text, input_text, _ = line.split(\"\\t\")\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = \"\\t\" + target_text + \"\\n\"\n",
        "    test_input_texts.append(input_text)\n",
        "    test_target_texts.append(target_text)\n",
        "test_max_encoder_seq_length = max([len(txt) for txt in test_input_texts])\n",
        "test_max_decoder_seq_length = max([len(txt) for txt in test_target_texts])\n",
        "test_encoder_input_data = np.zeros(\n",
        "    (len(test_input_texts), test_max_encoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "test_decoder_input_data = np.zeros(\n",
        "    (len(test_input_texts), test_max_decoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "test_decoder_target_data = np.zeros(\n",
        "    (len(test_input_texts), test_max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "for i, (input_text, target_text) in enumerate(zip(test_input_texts, test_target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        test_encoder_input_data[i, t] = input_token_index[char]\n",
        "    test_encoder_input_data[i, t + 1:] = input_token_index[\" \"]\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        test_decoder_input_data[i, t] = target_token_index[char]\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            test_decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    test_decoder_input_data[i, t + 1:] = target_token_index[\" \"]\n",
        "    test_decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
        "\n",
        "print('Calculating test accuracy')\n",
        "test_accuracy = {}\n",
        "for beamSize in range(1,5):\n",
        "  df = pd.DataFrame(columns=['SourceText', 'Prediction', 'GroundTruth'])\n",
        "  n_correct = 0\n",
        "  n_total = 0\n",
        "  for seq_index in range(len(test_encoder_input_data)):\n",
        "      decoded_sentence = model.beam_search(test_encoder_input_data[seq_index:seq_index+1], beam_size=beamSize)\n",
        "\n",
        "      if test_target_texts[seq_index].strip() == decoded_sentence[0][0].strip():\n",
        "          n_correct += 1\n",
        "\n",
        "      n_total += 1\n",
        "      row = {}\n",
        "      row['SourceText'] = test_input_texts[seq_index].strip()\n",
        "      row['GroundTruth'] = test_target_texts[seq_index].strip()\n",
        "      row['Prediction'] = decoded_sentence[0][0].strip()\n",
        "      df = df.append(row, ignore_index=True)\n",
        "  df.to_csv('predictions_'+str(beamSize)+'.csv', index=False)  \n",
        "  test_accuracy[beamSize] = (n_correct * 100.0 / n_total)\n",
        "print('Test accuracy ', test_accuracy)\n",
        "\n",
        "for beamSize in range(1,5):\n",
        "  files.download('predictions_'+str(beamSize)+'.csv')\n",
        "  time.sleep(30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['கடத்தி\\tkatatthi\\t1', 'ஊர்களிலும்\\toorkalilum\\t1']\n",
            "Number of samples: 68217\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 49\n",
            "Max sequence length for inputs: 30\n",
            "Max sequence length for outputs: 28\n",
            "{' ': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n",
            "{'\\t': 0, '\\n': 1, ' ': 2, 'ஃ': 3, 'அ': 4, 'ஆ': 5, 'இ': 6, 'ஈ': 7, 'உ': 8, 'ஊ': 9, 'எ': 10, 'ஏ': 11, 'ஐ': 12, 'ஒ': 13, 'ஓ': 14, 'க': 15, 'ங': 16, 'ச': 17, 'ஜ': 18, 'ஞ': 19, 'ட': 20, 'ண': 21, 'த': 22, 'ந': 23, 'ன': 24, 'ப': 25, 'ம': 26, 'ய': 27, 'ர': 28, 'ற': 29, 'ல': 30, 'ள': 31, 'ழ': 32, 'வ': 33, 'ஷ': 34, 'ஸ': 35, 'ஹ': 36, 'ா': 37, 'ி': 38, 'ீ': 39, 'ு': 40, 'ூ': 41, 'ெ': 42, 'ே': 43, 'ை': 44, 'ொ': 45, 'ோ': 46, 'ௌ': 47, '்': 48}\n",
            "Epoch 1/25\n",
            "1066/1066 [==============================] - 29s 21ms/step - loss: 0.9521 - accuracy: 0.7395\n",
            "Epoch 2/25\n",
            "1066/1066 [==============================] - 22s 21ms/step - loss: 0.3898 - accuracy: 0.8848\n",
            "Epoch 3/25\n",
            "1066/1066 [==============================] - 22s 21ms/step - loss: 0.1546 - accuracy: 0.9571\n",
            "Epoch 4/25\n",
            "1066/1066 [==============================] - 22s 21ms/step - loss: 0.0898 - accuracy: 0.9756\n",
            "Epoch 5/25\n",
            "1066/1066 [==============================] - 22s 21ms/step - loss: 0.0633 - accuracy: 0.9825\n",
            "Epoch 6/25\n",
            "1066/1066 [==============================] - 23s 21ms/step - loss: 0.0483 - accuracy: 0.9866\n",
            "Epoch 7/25\n",
            "1066/1066 [==============================] - 22s 21ms/step - loss: 0.0382 - accuracy: 0.9893\n",
            "Epoch 8/25\n",
            "1066/1066 [==============================] - 22s 21ms/step - loss: 0.0312 - accuracy: 0.9910\n",
            "Epoch 9/25\n",
            "1066/1066 [==============================] - 22s 21ms/step - loss: 0.0266 - accuracy: 0.9923\n",
            "Epoch 10/25\n",
            "1066/1066 [==============================] - 22s 21ms/step - loss: 0.0229 - accuracy: 0.9933\n",
            "Epoch 11/25\n",
            "1066/1066 [==============================] - 22s 21ms/step - loss: 0.0206 - accuracy: 0.9938\n",
            "Epoch 12/25\n",
            "1066/1066 [==============================] - 22s 21ms/step - loss: 0.0185 - accuracy: 0.9944\n",
            "Epoch 13/25\n",
            "1066/1066 [==============================] - 22s 21ms/step - loss: 0.0170 - accuracy: 0.9949\n",
            "Epoch 14/25\n",
            "1066/1066 [==============================] - 22s 21ms/step - loss: 0.0156 - accuracy: 0.9952\n",
            "Epoch 15/25\n",
            "1066/1066 [==============================] - 22s 21ms/step - loss: 0.0147 - accuracy: 0.9955\n",
            "Epoch 16/25\n",
            "1066/1066 [==============================] - 22s 21ms/step - loss: 0.0140 - accuracy: 0.9957\n",
            "Epoch 17/25\n",
            "1066/1066 [==============================] - 22s 21ms/step - loss: 0.0133 - accuracy: 0.9958\n",
            "Epoch 18/25\n",
            "1066/1066 [==============================] - 23s 21ms/step - loss: 0.0127 - accuracy: 0.9961\n",
            "Epoch 19/25\n",
            "1066/1066 [==============================] - 23s 21ms/step - loss: 0.0123 - accuracy: 0.9962\n",
            "Epoch 20/25\n",
            "1066/1066 [==============================] - 22s 21ms/step - loss: 0.0117 - accuracy: 0.9964\n",
            "Epoch 21/25\n",
            "1066/1066 [==============================] - 22s 21ms/step - loss: 0.0114 - accuracy: 0.9964\n",
            "Epoch 22/25\n",
            "1066/1066 [==============================] - 22s 21ms/step - loss: 0.0112 - accuracy: 0.9964\n",
            "Epoch 23/25\n",
            "1066/1066 [==============================] - 22s 21ms/step - loss: 0.0109 - accuracy: 0.9966\n",
            "Epoch 24/25\n",
            "1066/1066 [==============================] - 22s 21ms/step - loss: 0.0107 - accuracy: 0.9967\n",
            "Epoch 25/25\n",
            "1066/1066 [==============================] - 22s 21ms/step - loss: 0.0104 - accuracy: 0.9968\n",
            "Reading test data\n",
            "Calculating test accuracy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "L1KVS_qv4-3g",
        "outputId": "d0bf801e-213e-4015-89a7-bd1ddc371781"
      },
      "source": [
        "import time\n",
        "for beamSize in range(1,5):\n",
        "  files.download('predictions_'+str(beamSize)+'.csv')\n",
        "  time.sleep(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f6541e20-60d6-4bf3-90ef-be419a3a28c8\", \"predictions_1.csv\", 463)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_c2582f87-42a8-422b-8718-292b83ba8fa0\", \"predictions_2.csv\", 445)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_9aaef337-60c8-4cd3-9688-7f9d6df30c89\", \"predictions_3.csv\", 430)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_e1815012-6f13-49a4-8ec4-21b6e8a472ff\", \"predictions_4.csv\", 436)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kIQztpoHNs6",
        "outputId": "4d28640a-f66f-4b1d-ef33-a7d90a68786d"
      },
      "source": [
        "print(val_input_texts[0:5])\n",
        "print(val_target_texts[0:5])\n",
        "print(len(val_input_texts))\n",
        "print(len(val_target_texts))\n",
        "print(len(set(val_input_texts)))\n",
        "print(len(set(val_target_texts)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ankan', 'angkor', 'angira', 'angithi', 'angrej']\n",
            "['\\tअंकन\\n', '\\tअंगकोर\\n', '\\tअंगिरा\\n', '\\tअंगीठी\\n', '\\tअंग्रेज\\n']\n",
            "4357\n",
            "4357\n",
            "4320\n",
            "2500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvFeelJQ9eR9",
        "outputId": "e804c559-ca50-43e8-e787-73fac6b47516"
      },
      "source": [
        "subset = 200\n",
        "val_accuracy = model.accuracy(val_encoder_input_data[0:subset], val_target_texts[0:subset])\n",
        "print('Validation accuracy: ', val_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation accuracy:  15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DwoPFRh5waD",
        "outputId": "81edd87c-04a3-42fb-d4d6-3690f28965d1"
      },
      "source": [
        "model.decoder_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "decoder_input (InputLayer)      [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_embedding (Embedding)   (None, None, 32)     2112        decoder_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_hidden_1 (LSTM)         [(None, None, 256),  295936      decoder_embedding[1][0]          \n",
            "                                                                 input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_hidden_2 (LSTM)         [(None, None, 256),  525312      decoder_hidden_1[1][0]           \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output (Dense)          (None, None, 66)     16962       decoder_hidden_2[1][0]           \n",
            "==================================================================================================\n",
            "Total params: 840,322\n",
            "Trainable params: 840,322\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEk0woFkKyPy",
        "outputId": "1a410ff9-270b-4c42-b5b5-2dc0fd327e31"
      },
      "source": [
        "model.encoder_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "encoder_embedding (Embedding (None, None, 32)          864       \n",
            "_________________________________________________________________\n",
            "encoder_hidden_1 (GRU)       [(None, None, 256), (None 222720    \n",
            "=================================================================\n",
            "Total params: 223,584\n",
            "Trainable params: 223,584\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8Y1E7ooKZYG",
        "outputId": "e9baec3d-1eef-4b4a-d546-23f1dde2486f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_input (InputLayer)      [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_embedding (Embedding)   (None, None, 32)     864         encoder_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_input (InputLayer)      [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_hidden_1 (GRU)          [(None, None, 256),  222720      encoder_embedding[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "decoder_embedding (Embedding)   (None, None, 32)     2112        decoder_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "encoder_hidden_2 (GRU)          [(None, None, 256),  394752      encoder_hidden_1[0][0]           \n",
            "                                                                 encoder_hidden_1[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "decoder_hidden_1 (GRU)          [(None, None, 256),  222720      decoder_embedding[0][0]          \n",
            "                                                                 encoder_hidden_2[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "decoder_hidden_2 (GRU)          [(None, None, 256),  394752      decoder_hidden_1[0][0]           \n",
            "                                                                 encoder_hidden_2[0][1]           \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output (Dense)          (None, None, 66)     16962       decoder_hidden_2[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 1,254,882\n",
            "Trainable params: 1,254,882\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}